{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 320 - Final Tutorial - UMD Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_get_request(URL, headers=None, given_params=None):\n",
    "    \"\"\"Sends a GET request to the given URL.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    URL : str\n",
    "        The url to send a GET request\n",
    "    given_params : dictionary, optional\n",
    "        A dictionary of any additional parameters (default is None)\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "        A dictionary containing the JSON response\n",
    "    \"\"\"\n",
    "    \n",
    "    SUCCESS = 200\n",
    "    response = requests.get(URL, headers=headers, params=given_params)\n",
    "    \n",
    "    if (response.status_code == SUCCESS):\n",
    "        return response\n",
    "    else:\n",
    "        return {};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a database functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    conn = None\n",
    "    print(db_file)\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(conn, create_table_sql, params=()):\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql, params)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape and Parse Faculty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempted to use umd.io, but it appears to be rather glitchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "umd_professor_url = \"https://api.umd.io/v1/professors\";\n",
    "page = 1\n",
    "professorNames = set() \n",
    "params = {'departments': 'CMSC', 'page': page}\n",
    "\n",
    "json = make_get_request(umd_professor_url, params)\n",
    "professorNames.update([professor['name'] for professor in json])\n",
    "\n",
    "while json is not None:\n",
    "    page = page + 1\n",
    "    params['page'] = page\n",
    "    \n",
    "    json = make_get_request(umd_professor_url, params)\n",
    "    if json:\n",
    "        professorNames.update([professor['name'] for professor in json])\n",
    "        \n",
    "    print(professorNames)\n",
    "        \n",
    "# print(professorNames)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_names_filepath = os.path.abspath('./data/db/faculty_names.db')\n",
    "should_scrape_names = not path.exists(faculty_names_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape faculty from UMD faculty page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\",\n",
    "    \"Access-Control-Allow-Origin\": \"*\",\n",
    "    \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "    \"Access-Control-Allow-Methods\": \"GET\"\n",
    "}\n",
    "\n",
    "if should_scrape_names:\n",
    "    faculty_url = \"https://academiccatalog.umd.edu/undergraduate/administrators-officials-faculty/\"\n",
    "    response = make_get_request(faculty_url, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse each listing into a name, type, and college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name(name):\n",
    "    # Name structure: <last name>, <first name> (<middle name/initial>)\n",
    "    split = name.split(',')\n",
    "    last_name = split[0]\n",
    "    \n",
    "    first_name = split[1].split()[0]\n",
    "    \n",
    "    return (first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring those who don't fall into the colleges listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "colleges = ['AGNR', 'ARCH', 'ARHU', 'BSOS', 'BMGT', 'CMNS', 'EDUC', 'ENGR', 'JOUR', 'INFO', 'SPHL', 'PLCY']\n",
    "\n",
    "# Description format: Type, SCHOOL-DEPARTMENT (repeated); Degree, University, Year; (repeated)\n",
    "def create_faculty(name, description, faculty_dict):\n",
    "    (first_name, last_name) = split_name(name.strip())\n",
    "    \n",
    "    job_type = description.split(',')[0]\n",
    "    college_dept = description.split(',')[1]\n",
    "    \n",
    "    # Not currently using, but may switch to it\n",
    "    faculty_college = college_dept.split('-')[0].strip()\n",
    "    \n",
    "    prof_colleges = []\n",
    "    for college in colleges:\n",
    "        if college in college_dept:\n",
    "            prof_colleges.append(college)\n",
    "    \n",
    "    if prof_colleges:\n",
    "        faculty = {'first_name': first_name, 'last_name': last_name, 'colleges': prof_colleges, 'type': job_type}\n",
    "\n",
    "        if name not in faculty_dict:\n",
    "            key = last_name + \", \" + first_name\n",
    "            faculty_dict[key] = faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_names_from_db():\n",
    "    conn = create_connection(faculty_names_filepath)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM names\")\n",
    "    \n",
    "    all_faculty = {}\n",
    "    \n",
    "    for faculty in cursor.fetchall():\n",
    "        person = {'first_name': faculty[1], 'last_name': faculty[2], 'colleges': faculty[5], 'type': faculty[4]}\n",
    "        key = person[\"last_name\"] + \", \" + person[\"first_name\"]\n",
    "        all_faculty[key] = person\n",
    "        \n",
    "    return all_faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\UMD\\FALL_2020\\CMSC320\\final-tutorial\\data\\db\\faculty_names.db\n"
     ]
    }
   ],
   "source": [
    "if should_scrape_names:\n",
    "    faculty_blocks = soup.find_all(\"p\", class_=\"faculty-item\")\n",
    "\n",
    "    # Keeping track of only CS and ENGR professors, but this is arbitrary\n",
    "    CMNS_profs = set()\n",
    "    ENGR_profs = set()\n",
    "    all_faculty = {}\n",
    "\n",
    "    for block in faculty_blocks:\n",
    "\n",
    "        # Names are stored within the <strong/> tag\n",
    "        name = block.strong.string \n",
    "\n",
    "        # content structure: space,  name, space, <br/>, description\n",
    "        contents = block.contents\n",
    "        description = contents[4]\n",
    "\n",
    "        create_faculty(name, description, all_faculty)\n",
    "\n",
    "        if \"CMNS\" in description:\n",
    "            CMNS_profs.add(name)\n",
    "\n",
    "        elif \"ENGR\" in description:\n",
    "            ENGR_profs.add(name)\n",
    "else:\n",
    "    all_faculty = read_names_from_db()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'Mohammad', 'last_name': 'Teli', 'colleges': 'ENGR', 'type': 'Lecturer'}\n"
     ]
    }
   ],
   "source": [
    "print(all_faculty[\"Teli, Mohammad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a database holding faculty information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the first mentioned college for now, could switch later? Also only considering the colleges that were listed - others are ignored\n",
    "\n",
    "def create_names_table(conn):\n",
    "    names_table = \"\"\" CREATE TABLE IF NOT EXISTS names (\n",
    "                        id integer PRIMARY KEY,\n",
    "                        first_name text NOT NULL,\n",
    "                        last_name text NOT NULL,\n",
    "                        nick_name text,\n",
    "                        type text NOT NULL,\n",
    "                        college text NOT NULL,\n",
    "                        UNIQUE (first_name, last_name, type)\n",
    "                ) \"\"\"\n",
    "    create_table(conn, names_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_faculty_name(conn, faculty):\n",
    "    sql = \"\"\" INSERT OR IGNORE INTO names(first_name,last_name,type,college)\n",
    "                VALUES(?,?,?,?)\"\"\"\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, faculty)\n",
    "    conn.commit()\n",
    "    \n",
    "    return cursor.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\UMD\\FALL_2020\\CMSC320\\final-tutorial/data/db/faculty_names.db\n"
     ]
    }
   ],
   "source": [
    "faculty_names_path = os.path.abspath('.')\n",
    "faculty_names_path = faculty_names_path + \"/data/db/faculty_names.db\"\n",
    "faculty_names_db = create_connection(faculty_names_path)\n",
    "\n",
    "create_names_table(faculty_names_db)\n",
    "                                      \n",
    "\n",
    "for faculty_name in all_faculty:\n",
    "    faculty = all_faculty[faculty_name]\n",
    "    \n",
    "    if not faculty[\"colleges\"]:\n",
    "        college = None\n",
    "    else:\n",
    "        college = faculty[\"colleges\"][0]\n",
    "        \n",
    "    params = (faculty[\"first_name\"], faculty[\"last_name\"], faculty[\"type\"], college)\n",
    "    \n",
    "    insert_faculty_name(faculty_names_db, params)\n",
    "    \n",
    "faculty_names_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a database per professor for comments and submissions mentioning them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should only be done when a mention is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(name):\n",
    "    return ''.join(char for char in name if char.isalnum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_professor_tables(conn):\n",
    "    submissions_table = \"\"\" CREATE TABLE IF NOT EXISTS submissions (\n",
    "                            id integer PRIMARY KEY,\n",
    "                            sub_id text NOT NULL,\n",
    "                            title text NOT NULL,\n",
    "                            selftext text NOT NULL,\n",
    "                            score integer NOT NULL,\n",
    "                            full_link text NOT NULL,\n",
    "                            created_time integer NOT NULL,\n",
    "                            UNIQUE(sub_id)\n",
    "                        )\"\"\"\n",
    "    \n",
    "    comments_table = \"\"\" CREATE TABLE IF NOT EXISTS comments (\n",
    "                            id integer PRIMARY KEY,\n",
    "                            sub_id text NOT NULL,\n",
    "                            comment_id text NOT NULL,\n",
    "                            body text NOT NULL,\n",
    "                            score integer NOT NULL,\n",
    "                            created_time integer NOT NULL,\n",
    "                            UNIQUE(comment_id, sub_id)\n",
    "                    )\"\"\"\n",
    "    \n",
    "    create_table(conn, submissions_table)\n",
    "    create_table(conn, comments_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_professor_db(filename):\n",
    "    directory = os.path.abspath('.')\n",
    "    filepath = directory + \"\\data\\db\\professors\\\\\" + filename\n",
    "    \n",
    "    professor_db = create_connection(filepath)\n",
    "    \n",
    "    create_professor_tables(professor_db)\n",
    "    \n",
    "    return professor_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_submission(conn, values):\n",
    "    insert_sql = \"\"\"INSERT OR IGNORE INTO submissions (\n",
    "                        sub_id, title, selftext, score, full_link, created_time\n",
    "                    ) VALUES (?,?,?,?,?,?)\n",
    "                 \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(insert_sql, values)\n",
    "    conn.commit()\n",
    "    \n",
    "    return cursor.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_all_submissions(conn, df):\n",
    "    for idx, sub in df.iterrows():\n",
    "        insert_submission(conn, (sub['id'], sub['title'], sub['selftext'], sub['score'], sub['full_link'], sub['created_utc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This will create a database per professor immediately, no matter what. But we probably don't want that\n",
    "\"\"\"\n",
    "directory = os.path.abspath('.')\n",
    "directory = directory + \"\\data\\db\\professors\"\n",
    "\n",
    "for professor in all_faculty:\n",
    "    prof_name = split_name(professor)\n",
    "    prof_name = (normalize_name(prof_name[0]), normalize_name(prof_name[1]))\n",
    "    filename = prof_name[0] + \"_\" + prof_name[1] + \".db\" # first_last\n",
    "    \n",
    "    create_professor_db(filename)\n",
    "    \n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requesting Data from the UMD Subreddit with PushShift API and BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_college_query(college):\n",
    "    return \"({lower}|{upper})\".format(lower=college.lower(), upper=college)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_college_filename(college):\n",
    "    return normalize_name(college + \".db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "umd_subreddit = 'umd'\n",
    "min_count = 50\n",
    "\n",
    "sub_limit = 100\n",
    "sub_filter = ['title', 'selftext', 'score', 'full_link', 'id', 'created_utc']\n",
    "\n",
    "def query_submissions_mentioning_college(college):\n",
    "    query = form_college_query(college)\n",
    "    print(query)\n",
    "    \n",
    "    submissions = api.search_submissions(q=query, subreddit=umd_subreddit, filter=sub_filter, limit=sub_limit)\n",
    "    df = pd.DataFrame([thing.d_ for thing in submissions])\n",
    "    \n",
    "    if len(df.index) == min_count:\n",
    "        return df\n",
    "        \"\"\"\n",
    "        filename = make_professor_filename(professor)\n",
    "        prof_db = create_professor_db(filename)\n",
    "        \n",
    "        df['selftext'] = df['selftext'].apply(lambda x: x.replace(\"\\n\", \" \").replace(\"\\t\", \" \"))\n",
    "        insert_all_submissions(prof_db, df)\n",
    "        prof_db.close()\n",
    "        \"\"\"\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cmns|CMNS)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   created_utc  97 non-null     int64  \n",
      " 1   full_link    97 non-null     object \n",
      " 2   id           97 non-null     object \n",
      " 3   score        97 non-null     int64  \n",
      " 4   selftext     97 non-null     object \n",
      " 5   title        97 non-null     object \n",
      " 6   created      97 non-null     float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 5.4+ KB\n",
      "None\n",
      "(engr|ENGR)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   created_utc  16 non-null     int64  \n",
      " 1   full_link    16 non-null     object \n",
      " 2   id           16 non-null     object \n",
      " 3   score        16 non-null     int64  \n",
      " 4   selftext     16 non-null     object \n",
      " 5   title        16 non-null     object \n",
      " 6   created      16 non-null     float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 1.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cmns_df = query_submissions_mentioning_college('CMNS')\n",
    "\n",
    "print(cmns_df.info())\n",
    "\n",
    "engr_df = query_submissions_mentioning_college('ENGR')\n",
    "print(engr_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting data with the PushShift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_limit = 10\n",
    "comment_filter = ['body', 'score', 'created_utc', 'id', 'link_id']\n",
    "\n",
    "unmentioned_names = []\n",
    "\n",
    "query_all_professors = False\n",
    "\n",
    "if query_all_professors:\n",
    "    for professor_key in all_faculty:\n",
    "        professor = all_faculty[professor_key]\n",
    "        \n",
    "        query_submissions_mentioning_professor(professor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting stored data with Google's BigQuery and PushShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "teli_df = query_submissions_mentioning_professor(all_faculty[\"Teli, Mohammad\"])\n",
    "all_text = teli_df['selftext'].tolist() + teli_df['title'].tolist()\n",
    "clean_text = [re.sub(r'[^A-Za-z0-9 ]+', '', x).lower() for x in all_text]\n",
    "\n",
    "words_per_message = [text.split() for text in clean_text]\n",
    "\n",
    "all_words = list(itertools.chain(*words_per_message))\n",
    "\n",
    "count_all_words = collections.Counter(all_words)\n",
    "#print(count_all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "all_words = [word for word in all_words if word not in default_stopwords]\n",
    "\n",
    "# There is ConditionalFreqDist in NLTK that'll categorize words as well\n",
    "freqDist = nltk.FreqDist(all_words)\n",
    "\n",
    "#for word, freq in freqDist.most_common(50):\n",
    "    # print(\"{}: {}\".format(word, freq))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teli: 102\n",
      "class: 90\n",
      "351: 50\n",
      "semester: 49\n",
      "kruskal: 47\n",
      "im: 42\n",
      "take: 40\n",
      "exam: 40\n",
      "cmsc351: 31\n",
      "get: 30\n",
      "taking: 27\n",
      "would: 27\n",
      "cs: 24\n",
      "like: 23\n",
      "know: 22\n",
      "grade: 21\n",
      "section: 20\n",
      "also: 19\n",
      "cmsc: 19\n",
      "question: 18\n",
      "good: 18\n",
      "lecture: 18\n",
      "two: 17\n",
      "course: 17\n",
      "homework: 17\n",
      "next: 16\n",
      "pretty: 16\n",
      "lot: 16\n",
      "one: 16\n",
      "time: 16\n",
      "ta: 16\n",
      "teaching: 15\n",
      "really: 15\n",
      "much: 15\n",
      "dont: 15\n",
      "fall: 15\n",
      "people: 15\n",
      "got: 14\n",
      "professor: 14\n",
      "point: 14\n",
      "want: 13\n",
      "project: 13\n",
      "426: 13\n",
      "451: 13\n",
      "waitlist: 13\n",
      "hard: 13\n",
      "sure: 12\n",
      "telis: 12\n",
      "make: 12\n",
      "student: 12\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(word) if word != \"cs\" else word for word in all_words if word not in default_stopwords]\n",
    "\n",
    "freqDistLemmas = nltk.FreqDist(lemmas)\n",
    "\n",
    "for lemma, freq in freqDistLemmas.most_common(50):\n",
    "    print(\"{}: {}\".format(lemma, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could also use bi or tri-gram analysis with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large query of multiple CS professors and X professors. Equal amounts of both\n",
    "\n",
    "How often are negative/postive terms used with these departments? But where's the machine learning....?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More NLP-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large query of all CMSC/CMNS professors + terms of 'CS', 'CMSC', and 'CMNS'\n",
    "\n",
    "Large query of all X department professors + X terms\n",
    "\n",
    "Equal amounts of both. ~500 of each? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
