{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Computer Science versus Business Management Introductory Course Professors Reviews and Their Trends Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "William Ingold, Erik Kelemen, Ashish Manda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Introductory Course Professors From UMD.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "professors_url = \"https://api.umd.io/v1/professors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for saving professor data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import path\n",
    "\n",
    "cmsc_professor_names_filepath = './data/cmsc_professor_names.csv'\n",
    "bmgt_professor_names_filepath = './data/bmgt_professor_names.csv'\n",
    "\n",
    "have_cmsc_professors = path.exists(cmsc_professor_names_filepath)\n",
    "have_bmgt_professors = path.exists(bmgt_professor_names_filepath)\n",
    "\n",
    "def read_professor_name_data(professor_filepath):\n",
    "    \"\"\"Reads the professor names and their courses from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professor_filepath: String holding a filepath to the professor csv file.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of professor names to a set of courses they have taught.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(professor_filepath, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "\n",
    "        professors = {}\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if line_count != 0:\n",
    "                professors[row['name']] = set([course for course in row['courses'].split(' ')])\n",
    "            line_count += 1\n",
    "\n",
    "        return professors\n",
    "\n",
    "def save_professor_data(professors, filepath):\n",
    "    \"\"\"Saves the professor names and their courses to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professors: A dictionary of professor name keys and a set of courses for values.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = ['name', 'courses']\n",
    "    try:\n",
    "        with open(filepath, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for name, courses in professors.items():\n",
    "                writer.writerow({'name': name, 'courses': ' '.join(courses)})\n",
    "                \n",
    "    except IOError:\n",
    "        print(\"Error in writing the CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility to actually grab professors based on a list of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_professors_for_courses(course_ids):\n",
    "    \"\"\"Gets all the professors for the given course_ids and returns a list of them.\n",
    "    \n",
    "    Args:\n",
    "        course_ids: A list of course ids (e.g. ['CMSC216', CMSC250']).\n",
    "        \n",
    "    Returns:\n",
    "        List of professors that teach the given courses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    professors = {}\n",
    "    \n",
    "    for course_id in course_ids:\n",
    "        params = {'course_id': course_id}\n",
    "\n",
    "        response = requests.get(professors_url, params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "\n",
    "            for item in response.json():\n",
    "                name = item['name']\n",
    "\n",
    "                if name in professors:\n",
    "                    professors[name].add(course_id)\n",
    "                else:\n",
    "                    professors[name] = {course_id}\n",
    "\n",
    "    return professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Computer Science Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fawzi Emad': {'CMSC250', 'CMSC131', 'CMSC132'}, 'Ilchul Yoon': {'CMSC216', 'CMSC131', 'CMSC132'}, 'Nelson Padua-Perez': {'CMSC216', 'CMSC131', 'CMSC132'}, 'Pedram Sadeghian': {'CMSC131', 'CMSC132'}, 'Anwar Mamat': {'CMSC132'}, 'Laurence Herman': {'CMSC216', 'CMSC132'}, 'A Shankar': {'CMSC216'}, 'Aditya Acharya': {'CMSC250'}, 'Alexander Brassel': {'CMSC250'}, 'Clyde Kruskal': {'CMSC250'}, 'David Sekora': {'CMSC250'}, 'Donald Perlis': {'CMSC250'}, 'Jason Filippou': {'CMSC250'}, 'Mohammad Nayeem Teli': {'CMSC250'}, 'Roger Eastman': {'CMSC250'}}\n"
     ]
    }
   ],
   "source": [
    "# TODO: What about honors?\n",
    "cmsc_course_ids = [\"CMSC131\", \"CMSC132\", \"CMSC216\", \"CMSC250\"]\n",
    "\n",
    "# TODO: Dr. Eastman has taught CMSC131, per RateMyProfessor, but wasn't given via UMD.IO\n",
    "\n",
    "# Only query the UMD.io API if we don't have the data\n",
    "if not have_cmsc_professors:\n",
    "    cmsc_professors = get_professors_for_courses(cmsc_course_ids)\n",
    "    save_professor_data(cmsc_professors, cmsc_professor_names_filepath)\n",
    "    have_cmsc_professors = True\n",
    "else: \n",
    "    cmsc_professors = read_professor_name_data(cmsc_professor_names_filepath)\n",
    "\n",
    "    if not cmsc_professors:\n",
    "        print(\"Error response from umd.io API\")\n",
    "\n",
    "if 'Iason Filippou' in cmsc_professors:\n",
    "    cmsc_professors.pop('Iason Filippou') # A typo of Jason Filippou from the database\n",
    "    \n",
    "print(cmsc_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Business Management Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jeff Miller': {'BMGT110'}, 'Cody Hyman': {'BMGT220'}, 'Laurel Mazur': {'BMGT221', 'BMGT220'}, 'Progyan Basu': {'BMGT220'}, 'Viktoriya Zotova': {'BMGT220'}, 'Gary Bulmash': {'BMGT221'}, 'Gerald Ward': {'BMGT221'}, 'Ai Ren': {'BMGT230'}, 'Daehoon Noh': {'BMGT230'}, 'Erich Studer-Ellis': {'BMGT230'}, 'Huan Cao': {'BMGT230'}, 'Radu Lazar': {'BMGT230'}, 'Shubham Akshat': {'BMGT230'}, 'Ziwei Cao': {'BMGT230'}}\n"
     ]
    }
   ],
   "source": [
    "# TODO: What about honors?\n",
    "bmgt_course_ids = [\"BMGT110\", \"BMGT220\", \"BMGT221\", \"BMGT230\"]\n",
    "\n",
    "# Only query the UMD.io API if we don't have the data\n",
    "if not have_bmgt_professors:\n",
    "    bmgt_professors = get_professors_for_courses(bmgt_course_ids)\n",
    "    save_professor_data(bmgt_professors, bmgt_professor_names_filepath)\n",
    "    have_bmgt_professors = True\n",
    "else:\n",
    "    bmgt_professors = read_professor_name_data(bmgt_professor_names_filepath)\n",
    "\n",
    "    if not bmgt_professors:\n",
    "        print(\"Error response from umd.io API\")\n",
    "\n",
    "print(bmgt_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Databases to Hold Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# Setup database presets\n",
    "db_filepath = './data/db/'\n",
    "bmgt_rmp_db_filepath = db_filepath + 'bmgt_rmp.db'\n",
    "cmsc_rmp_db_filepath = db_filepath + 'cmsc_rmp.db'\n",
    "\n",
    "bmgt_pt_db_filepath = db_filepath + 'bmgt_pt.db'\n",
    "cmsc_pt_db_filepath = db_filepath + 'cmsc_pt.db'\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\"Create a connection to the provided database file.\n",
    "    \n",
    "    Args:\n",
    "        db_file: A string holding the filepath to a database.\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    print(db_file)\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def execute_create_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    \n",
    "def execute_insert_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        conn.commit()\n",
    "        \n",
    "        return c.lastrowid\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def execute_query_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        \n",
    "        return c.fetchall()\n",
    "    \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def is_professor_scraped(db_conn, professor_name):\n",
    "    \"\"\"Returns if the professor's RateMyProfessors page has been scraped already.\n",
    "    \n",
    "    Args:\n",
    "        db_conn: Connection object to the appropriate database.\n",
    "        professor_name: String holding the professor's name.\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_command = \"\"\"SELECT\n",
    "                        full_name\n",
    "                    FROM\n",
    "                        professor_stats ps\n",
    "                    WHERE\n",
    "                        full_name LIKE ?\"\"\"\n",
    "    \n",
    "    params=('%'+professor_name+'%',)\n",
    "    \n",
    "    result = execute_query_command(db_conn, sql_command, params)\n",
    "    \n",
    "    return len(result) != 0\n",
    "\n",
    "\n",
    "def get_professor_stats_from_db(db_conn, professor):\n",
    "    \"\"\"Reads the professor_stats table into a pandas dataframe and returns it.\"\"\"\n",
    "    \n",
    "    sql_query = \"\"\"SELECT * FROM professor_stats WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[professor])\n",
    "\n",
    "def get_professor_reviews_from_db(db_conn, professor):\n",
    "    \"\"\"Reads the reviews table into a pandas dataframe and returns it.\"\"\"\n",
    "    \n",
    "    sql_query = \"\"\"SELECT * FROM reviews WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, db_conn, params=[professor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RateMyProfessor Specific Database Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/db/cmsc_rmp.db\n",
      "./data/db/bmgt_rmp.db\n"
     ]
    }
   ],
   "source": [
    "def create_rmp_tables(rmp_conn):\n",
    "    \"\"\"Create the stats and review tables for RateMyProfessors data.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessors database.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_table = \"\"\" CREATE TABLE IF NOT EXISTS professor_stats (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        page_exists INTEGER NOT NULL,\n",
    "                        rating REAL,\n",
    "                        take_again REAL,\n",
    "                        difficulty REAL,\n",
    "                        rating_count INTEGER NOT NULL,\n",
    "                        gives_good_feedback INTEGER,\n",
    "                        respected INTEGER,\n",
    "                        lots_of_homework INTEGER,\n",
    "                        accessible_outside_class INTEGER,\n",
    "                        get_ready_to_read INTEGER,\n",
    "                        participation_matters INTEGER,\n",
    "                        skip_class_wont_pass INTEGER,\n",
    "                        inspirational INTEGER,\n",
    "                        graded_by_few_things INTEGER,\n",
    "                        test_heavy INTEGER,\n",
    "                        group_projects INTEGER,\n",
    "                        clear_grading_criteria INTEGER,\n",
    "                        hilarious INTEGER,\n",
    "                        beware_of_pop_quizes INTEGER,\n",
    "                        amazing_lectures INTEGER,\n",
    "                        lecture_heavy INTEGER,\n",
    "                        caring INTEGER,\n",
    "                        extra_credit INTEGER,\n",
    "                        so_many_papers INTEGER,\n",
    "                        tough_grader INTEGER\n",
    "                    ) \"\"\"\n",
    "    \n",
    "    # Review id format <professor last name>-<#> \n",
    "    review_table = \"\"\" CREATE TABLE IF NOT EXISTS reviews (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        review_id TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL,\n",
    "                        course TEXT NOT NULL,\n",
    "                        date INTEGER NOT NULL,\n",
    "                        body TEXT NOT NULL,\n",
    "                        thumb_up INTEGER,\n",
    "                        thumb_down INTEGER,\n",
    "                        quality REAL NOT NULL,\n",
    "                        difficulty REAL NOT NULL,\n",
    "                        would_take_again INTEGER NOT NULL,\n",
    "                        for_credit INTEGER NOT NULL,\n",
    "                        textbook INTEGER NOT NULL,\n",
    "                        attendance INTEGER,\n",
    "                        grade TEXT,\n",
    "                        online_class INTEGER,\n",
    "                        gives_good_feedback INTEGER,\n",
    "                        respected INTEGER,\n",
    "                        lots_of_homework INTEGER,\n",
    "                        accessible_outside_class INTEGER,\n",
    "                        get_ready_to_read INTEGER,\n",
    "                        participation_matters INTEGER,\n",
    "                        skip_class_wont_pass INTEGER,\n",
    "                        inspirational INTEGER,\n",
    "                        graded_by_few_things INTEGER,\n",
    "                        test_heavy INTEGER,\n",
    "                        group_projects INTEGER,\n",
    "                        clear_grading_criteria INTEGER,\n",
    "                        hilarious INTEGER,\n",
    "                        beware_of_pop_quizes INTEGER,\n",
    "                        amazing_lectures INTEGER,\n",
    "                        lecture_heavy INTEGER,\n",
    "                        caring INTEGER,\n",
    "                        extra_credit INTEGER,\n",
    "                        so_many_papers INTEGER,\n",
    "                        tough_grader INTEGER\n",
    "                   ) \"\"\"\n",
    "    \n",
    "    execute_create_command(rmp_conn, stats_table)\n",
    "    execute_create_command(rmp_conn, review_table)\n",
    "\n",
    "# Create the CMSC and BMGT database with the two tables\n",
    "cmsc_rmp_db = create_connection(cmsc_rmp_db_filepath)\n",
    "bmgt_rmp_db = create_connection(bmgt_rmp_db_filepath)\n",
    "\n",
    "create_rmp_tables(cmsc_rmp_db)\n",
    "create_rmp_tables(bmgt_rmp_db)\n",
    "\n",
    "# Close for now, will reopen when writing to them\n",
    "cmsc_rmp_db.close()\n",
    "bmgt_rmp_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using dataframes, but single table to hold all stats and reviews instead of individual tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_rmp_dataframe_insert(rmp_conn, table_name, column_list, values):\n",
    "    \"\"\"Executes an insert to the provided database and table, using the\n",
    "    column headers and values provided as well.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessor database.\n",
    "        table_name: String holding a table name to insert into ('reviews' or 'professor_stats')\n",
    "        values: List of values corresponding to the column headers to insert.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Question mark for each value to be filled, don't want a trailing comma\n",
    "    question_marks = \"?,\" * (len(column_list) - 1)\n",
    "    question_marks = question_marks + \"?\"\n",
    "    \n",
    "    column_names = \",\".join(column_list)\n",
    "    \n",
    "    insert_rmp_sql = \"\"\"INSERT INTO {table_name} (\n",
    "                                {column_names}\n",
    "                           )\n",
    "                           VALUES({question_marks})\n",
    "                           \"\"\".format(table_name=table_name, question_marks=question_marks, column_names=column_names)\n",
    "    \n",
    "    # TODO: Need to surround with % ?\n",
    "    values = tuple(values)\n",
    "    \n",
    "    return execute_insert_command(rmp_conn, insert_rmp_sql, values)\n",
    "    \n",
    "    \n",
    "def insert_rmp_professor_dataframe(rmp_conn, df, table_name):\n",
    "    \"\"\"Inserts all rows of a given dataframe to the RMP database's table.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessor database.\n",
    "        df: Pandas DataFrame object containing data to insert.\n",
    "        table_name: String holding a table name to insert into ('reviews' or 'professor_stats')\n",
    "    \"\"\"\n",
    "    \n",
    "    column_list = list(df.columns)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        execute_rmp_dataframe_insert(rmp_conn, table_name, column_list, row.array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO: Alternative database structure, where each professor has its own tables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_rmp_professor_overall_table(rmp_conn, professor_name, overall_df):\n",
    "    table_name = professor_name + \"_stats\"\n",
    "    overall_df.to_sql(table_name, con=rmp_conn, if_exists='append')\n",
    "    \n",
    "def insert_rmp_professor_reviews_table(rmp_conn, professor_name, review_df):\n",
    "    table_name = professor_name + \"_reviews\"\n",
    "    review_df.to_sql(table_name, con=rmp_conn, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlanetTerp Database Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "base_grades = ['A', 'B', 'C', 'D', 'F']\n",
    "grade_possibilities = list(chain(*([x + '+', x, x + '-'] for x in base_grades)))\n",
    "\n",
    "def create_pt_tables(pt_conn):\n",
    "    \"\"\"Create the stats and review tables for RateMyProfessors data.\n",
    "    \n",
    "    Args:\n",
    "        pt_conn: Connection object to a PlanetTerp database.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Keep track of grade distribution in this table?\n",
    "    stats_table = \"\"\" CREATE TABLE IF NOT EXISTS professor_stats (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        slug TEXT NOT NULL,\n",
    "                        review_count INTEGER NOT NULL,\n",
    "                        type TEXT\n",
    "                    ) \"\"\"\n",
    "    \n",
    "    # TODO: Review id format? <professor last name>-<#> ?\n",
    "    review_table = \"\"\" CREATE TABLE IF NOT EXISTS reviews (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        review_id TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL,\n",
    "                        course TEXT NOT NULL,\n",
    "                        date INTEGER NOT NULL,\n",
    "                        body TEXT NOT NULL,\n",
    "                        rating INTEGER NOT NULL,\n",
    "                        expected_grade TEXT NOT NULL,\n",
    "                   ) \"\"\"\n",
    "    \n",
    "    execute_create_command(pt_conn, stats_table)\n",
    "    execute_create_command(pt_conn, review_table)\n",
    "\n",
    "# Create the CMSC and BMGT database with the two tables\n",
    "cmsc_pt_db = create_connection(cmsc_pt_db_filepath)\n",
    "bmgt_pt_db = create_connection(bmgt_pt_db_filepath)\n",
    "\n",
    "create_pt_tables(cmsc_pt_db)\n",
    "create_pt_tables(bmgt_pt_db)\n",
    "\n",
    "# Close for now, will reopen when writing to them\n",
    "cmsc_pt_db.close()\n",
    "bmgt_pt_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Parse Data from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data needed for requesting data from RateMyProfessor\n",
    "ratemyprofessor_url = \"https://www.ratemyprofessors.com/search.jsp\"\n",
    "params = {'queryoption':'HEADER', 'schoolID':'1270', 'queryBy':'teacherName', 'schoolName':'University+of+Maryland'}\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\",\n",
    "    \"Access-Control-Allow-Origin\": \"*\",\n",
    "    \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "    \"Access-Control-Allow-Methods\": \"GET\"\n",
    "}\n",
    "\n",
    "\n",
    "# List of tags that RateMyProfessor uses to describe professors, which are used for the database and dataframes\n",
    "tag_list = ['gives_good_feedback', 'respected', 'lots_of_homework', 'accessible_outside_class',\n",
    "           'get_ready_to_read', 'participation_matters', 'inspirational',\n",
    "           'graded_by_few_things', 'test_heavy', 'group_projects', 'clear_grading_criteria', \n",
    "           'hilarious', 'beware_of_pop_quizes', 'amazing_lectures', 'lecture_heavy', 'caring',\n",
    "           'extra_credit', 'so_many_papers', 'tough_grader', 'skip_class_wont_pass']\n",
    "\n",
    "# Want to tie the code friendly tag names to what is found on a RateMyProfessor page\n",
    "text_tag_list = [' '.join(x.split('_')) for x in tag_list]\n",
    "text_tag_list.remove('skip class wont pass')\n",
    "text_tag_list.append(\"skip class? you won't pass.\")\n",
    "\n",
    "# both tag_list and text_tag_list in same order, and correspond to one another\n",
    "text_tag_dict = {text_tag_list[i]: tag_list[i] for i in range(len(text_tag_list))}\n",
    "\n",
    "# These are the column headers for a professor's overall statistics found at the top of the page\n",
    "overall_header_list = ['first_name', 'last_name', 'full_name', 'page_exists', 'rating', 'take_again', 'difficulty',\n",
    "                      'rating_count'] + tag_list\n",
    "\n",
    "# Review post column headers. The meta list is the row of top meta responses (like 'Grade: A-').\n",
    "review_meta_list = ['would_take_again', 'grade', 'textbook', 'online_class', 'for_credit', 'attendance']\n",
    "review_text_meta_list = [' '.join(x.split('_')) for x in review_meta_list]\n",
    "review_meta_dict = {review_text_meta_list[i]: review_meta_list[i] for i in range(len(review_meta_list))}\n",
    "        \n",
    "review_header_list = ['review_id', 'course', 'date', 'quality', 'difficulty', 'body',\n",
    "                      'thumb_up', 'thumb_down'] + review_meta_list + tag_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_dict(provided_tags):\n",
    "    \"\"\"Turns the list of text tags (e.g. skip class? you won't pass) into a dictionary\n",
    "    of approriately named tags that work for database columns and if they were present.\n",
    "    \n",
    "    Args:\n",
    "        provided_tags: A list of space separated tags scraped from the RMP page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of {tag: 1 or 0} on whether a tag was used to describe the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_dict = {val: 0 for val in text_tag_dict.values()}\n",
    "    \n",
    "    for tag in provided_tags:\n",
    "        if tag.lower() in text_tag_dict.keys():\n",
    "            tag_dict[text_tag_dict[tag.lower()]] = 1\n",
    "            \n",
    "    return tag_dict\n",
    "\n",
    "def meta_to_dict(provided_meta):\n",
    "    \"\"\"Turns the dictionary of meta tags (e.g. Would Take Again: No) into a dictionary\n",
    "    of appropriately named tags that work for database columns and values if they were present.\n",
    "    \n",
    "    Args:\n",
    "        provided_meta: A dictionary of meta information from a review.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of {meta: 1 or 0} on whether a meta was used on the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    meta_dict = {val: 0 for val in review_meta_list}\n",
    "    \n",
    "    for meta, response in provided_meta.items():\n",
    "        value = 0\n",
    "        \n",
    "        if meta.lower() in review_meta_dict.keys():\n",
    "            \n",
    "            if response.lower() == \"yes\" or response.lower() == \"mandatory\":\n",
    "                value = 1\n",
    "                \n",
    "            if meta.lower() == \"grade\":\n",
    "                value = response\n",
    "            \n",
    "            meta_dict[review_meta_dict[meta.lower()]] = value\n",
    "            \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying RateMyProfessor and Getting the Professor's URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rmp_professor_url(html_doc):\n",
    "    \"\"\"Finds the professor's URL on the search page and returns it.\n",
    "    \n",
    "    Args:\n",
    "        html_doc: A string containing an HTML document.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page (if found).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    no_results = soup.find('div[class*=\"NoResultsFoundArea__StyledNoResultsFound\"]')\n",
    "    partial_url = soup.find('li', class_='listing PROFESSOR')\n",
    "    \n",
    "    # Sometimes RMP does the search differntly, so it'll be elsewhere\n",
    "    diff_location = soup.find('a', attrs={'class': lambda x: 'TeacherCard__StyledTeacherCard' in x if x else False}, href=True)\n",
    "    \n",
    "    # The professor may not be reviewed\n",
    "    if no_results is None and partial_url and len(partial_url) != 0:\n",
    "        if diff_location:\n",
    "            partial_url = diff_location['href']\n",
    "        else:\n",
    "            partial_url = partial_url.find('a', href=True)\n",
    "\n",
    "        if partial_url:\n",
    "            main_url = \"https://www.ratemyprofessors.com\"\n",
    "            return main_url + partial_url['href']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def query_rmp_for_professor_url(professor_name, headers, params):\n",
    "    \"\"\"Queries RateMyProfessor for the professor, given the parameters and headers.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: The <first name> <last name> of the professor.\n",
    "        headers: Dictionary of headers for the get request.\n",
    "        params: Dictionary of parameters for the get request.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page after searching for it (if found).\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    params['query'] = professor_name\n",
    "    \n",
    "    response = requests.get(ratemyprofessor_url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        url = find_rmp_professor_url(response.text)\n",
    "        \n",
    "        if url is not None:\n",
    "            return url\n",
    "        else:\n",
    "            print(\"Professor {name} has not been reviewed.\".format(name=professor_name))\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing the Professor Overall Information (Stats and Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_stats(page_text):\n",
    "    \"\"\"Parses the professor's stats from their page and returns them. Namely their overall rating, \n",
    "    how many would take again, overall difficulty and how many ratings they have on RateMyProfessor.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing their rating, take again percentage, difficulty rating, and rating count.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    rating_score = soup.select('div[class*=\"RatingValue__Numerator\"]')\n",
    "    \n",
    "    if rating_score is not None:\n",
    "        rating_score = float(rating_score[0].text)\n",
    "    else:\n",
    "        print('Rating score error: \\n')\n",
    "        print(soup)\n",
    "    \n",
    "    feedback = soup.select('div[class*=\"TeacherFeedback__StyledTeacherFeedback\"]')[0].select('div[class*=\"FeedbackItem__FeedbackNumber\"]')\n",
    "    \n",
    "    take_again = float(feedback[0].text[:-1]) / 100\n",
    "    difficulty = float(feedback[1].text)\n",
    "    \n",
    "    rating_count = soup.select('div[class*=\"RatingValue__NumRatings\"]')[0].select('a')[0].text\n",
    "    rating_count = ''.join([x for x in rating_count if x.isdigit()])\n",
    "    rating_count = int(rating_count)\n",
    "    \n",
    "    return {'rating': rating_score, 'take_again': take_again, 'difficulty': difficulty, 'rating_count': rating_count}\n",
    "\n",
    "\n",
    "def get_rmp_prof_top_tags(page_text):\n",
    "    \"\"\"Parses and returns the professor's top tags.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tags describing the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    tags = []\n",
    "    unparsed_tags = soup.select('div[class*=\"TeacherTags__TagsContainer\"]')\n",
    "    \n",
    "    if unparsed_tags and len(unparsed_tags) != 0:\n",
    "        unparsed_tags = unparsed_tags[0].select('span')\n",
    "    \n",
    "        for tag in unparsed_tags:\n",
    "            tags.append(tag.text)\n",
    "        \n",
    "    return tags_to_dict(tags)\n",
    "\n",
    "\n",
    "def rmp_prof_overall_to_dataframe(professor_name, stats, tags, page_exists=1):\n",
    "    \"\"\"Combines the professor's overall stats and tags into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: String holding the professor's name.\n",
    "        stats: A dictionary holding the overall stats (e.g. 'would_take_again': .83).\n",
    "        tags: A dictionary holding the tags associated with a professor (e.g. {'caring': 1}).\n",
    "        page_exists (optional, default=1): Integer boolean determining if a professor has a RMP page.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing the combination of professor name, stats, and tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    overall_df = pd.DataFrame(columns=overall_header_list)\n",
    "    \n",
    "    first_name, last_name = professor_name.split(' ', 1)\n",
    "    overall_dict = {'first_name': first_name, 'last_name': last_name, 'full_name': professor_name, 'page_exists': page_exists}\n",
    "    \n",
    "    overall_dict.update(stats)\n",
    "    overall_dict.update(tags)\n",
    "    \n",
    "    overall_df = overall_df.append(overall_dict, ignore_index=True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Selenium to Load All Professor Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_selenium():\n",
    "    \"\"\"Starts up the Selenium browser.\"\"\"\n",
    "    driver = webdriver.Firefox(executable_path='./bin/geckodriver.exe')\n",
    "    return driver\n",
    "    \n",
    "def stop_selenium(driver):\n",
    "    \"\"\"Shutdown the Selenium browser.\"\"\"\n",
    "    driver.close()\n",
    "    driver.quit()\n",
    "    \n",
    "def load_all_rmp_reviews(page_url, driver):\n",
    "    \"\"\"Loads all the reviews for a given porfessor and returns the text of all of them.\n",
    "    \n",
    "    Args:\n",
    "        page_url: The URL for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the HTML for all the reviews.\n",
    "    \"\"\"\n",
    "\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # RateMyProfessors has a cookies pop up that overlays the website, it needs to be closed first\n",
    "    time.sleep(0.5)\n",
    "    close_cookies = driver.find_elements(By.XPATH, '//button[text()=\"Close\"]')\n",
    "    \n",
    "    if close_cookies:\n",
    "        close_cookies[0].click()\n",
    "        \n",
    "    load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "    \n",
    "    # RateMyProfessors paginates the reviews via Javascript, so we must continually load more while the button is present\n",
    "    while load_more:\n",
    "        load_more[0].click()\n",
    "        time.sleep(1)\n",
    "        load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "        \n",
    "        \n",
    "    all_reviews = driver.find_element_by_id('ratingsList').get_attribute('outerHTML')\n",
    "    \n",
    "    \n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Utilities for a Single Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def string_date_to_unix(date_str):\n",
    "    \"\"\"Turns the RateMyProfessor date format (e.g. Nov 23rd, 2020) into a\n",
    "    UTC timestamp. Assumes the date is already in UTC.\n",
    "    \n",
    "    Args:\n",
    "        date_str: A string containing the RateMyProfessor review date.\n",
    "        \n",
    "    Returns:\n",
    "        A UTC timestamp corresponding to the date provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split into month, day, year\n",
    "    date_split = date_str.split(' ')\n",
    "    day = date_split[1]\n",
    "    \n",
    "    # Remove comma and suffix for day\n",
    "    day = day[:-3]\n",
    "    \n",
    "    # Place the day back into the list and join everything back together\n",
    "    date_split[1] = day\n",
    "    remade_date_str = (' ').join(date_split)\n",
    "    \n",
    "    # Change into UTC time\n",
    "    datetime_obj = datetime.datetime.strptime(remade_date_str, '%b %d %Y')\n",
    "    utc_time = datetime_obj.timestamp()\n",
    "    \n",
    "    return utc_time\n",
    "    \n",
    "def parse_rating_header(soup):\n",
    "    \"\"\"Parses and returns the rating header for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the course and date for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_header = soup.select('div[class*=\"Rating__RatingInfo\"]')\n",
    "    \n",
    "    if len(rating_header) != 0:\n",
    "        course = rating_header[0].select('div[class*=\"RatingHeader__StyledClass\"]')[0].text.strip()\n",
    "        date = rating_header[0].select('div[class*=\"TimeStamp__StyledTimeStamp\"]')[0].text.strip()\n",
    "        \n",
    "        utc_time = string_date_to_unix(date)\n",
    "    else:\n",
    "        print(soup)\n",
    "    \n",
    "    return {'course': course, 'date': utc_time}\n",
    "\n",
    "def parse_meta_data(soup):\n",
    "    \"\"\"Parses and returns the meta data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data (e.g. Would Take Again) for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    course_meta = soup.select('div[class*=\"CourseMeta__StyledCourseMeta\"]')[0]\n",
    "    review_meta_data = {}\n",
    "\n",
    "    for meta_div in course_meta.select('div'):\n",
    "        meta_data = meta_div.text.split(':')\n",
    "        meta_name = meta_data[0].strip()\n",
    "        meta_value = meta_data[1].strip()\n",
    "\n",
    "        review_meta_data[meta_name] = meta_value\n",
    "\n",
    "    return meta_to_dict(review_meta_data)\n",
    "\n",
    "def parse_rating_data(soup):\n",
    "    \"\"\"Parses and returns the rating data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the rating data for the quality and difficulty for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_values_text = soup.select('div[class*=\"RatingValues__StyledRatingValues\"]')[0].select('div[class*=\"RatingValues__RatingValue\"]')\n",
    "    quality = rating_values_text[0].text\n",
    "    difficulty = rating_values_text[1].text\n",
    "\n",
    "    rating_data = {'quality': quality, 'difficulty': difficulty}\n",
    "    \n",
    "    return rating_data\n",
    "\n",
    "def parse_review_tags(soup):\n",
    "    \"\"\"Parses and returns the tags for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list containing the tags for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_container = soup.select('div[class*=\"RatingTags__StyledTags\"]')\n",
    "    tags = []\n",
    "    \n",
    "    if tag_container: # Since not all reviews add tags\n",
    "        unparsed_tags = tag_container[0].select('span')\n",
    "\n",
    "        for tag in unparsed_tags:\n",
    "            tags.append(tag.text)\n",
    "\n",
    "    return tags_to_dict(tags)\n",
    "    \n",
    "def parse_thumb_scoring(soup):\n",
    "    \"\"\"Parses and returns the thumb scoring data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the thumb scoring data for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    thumb_container = soup.select('div[class*=\"RatingFooter__StyledRatingFooter\"]')[0].select('div[class*=\"RatingFooter__HelpTotal\"]')\n",
    "\n",
    "    thumb_up = int(thumb_container[0].text.strip())\n",
    "    thumb_down = int(thumb_container[1].text.strip())\n",
    "    thumb_data = {'thumb_up': thumb_up, 'thumb_down': thumb_down}\n",
    "\n",
    "    return thumb_data\n",
    "\n",
    "def parse_review_text(soup):\n",
    "    \"\"\"Parses and returns the review body text for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the review text for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_text = soup.select('div[class*=\"Comments__StyledComments\"]')[0].text\n",
    "    \n",
    "    return {'body': review_text}\n",
    "    \n",
    "def parse_single_rmp_review(review_item, courses):\n",
    "    \"\"\"Parses and returns all data for a single review.\n",
    "    Namely it returns: Meta data, rating data, tags, thumb_scoring, and review text.\n",
    "    \n",
    "    Args:\n",
    "        review_item: A single review list item containing all the appropraite HTML.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data, rating data, tags, thumb_scoring, and review text\n",
    "        for a single review.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(review_item, 'html.parser')\n",
    "    \n",
    "    course_and_date = parse_rating_header(soup)\n",
    "    \n",
    "    # TODO: Loses course reviews like 'CMSC131CMSC132' where students combined multiple courses they took\n",
    "    if course_and_date['course'] in courses:\n",
    "        \n",
    "        # Meta data\n",
    "        meta_data = parse_meta_data(soup)\n",
    "        \n",
    "        # Rating data\n",
    "        rating_data = parse_rating_data(soup)\n",
    "        \n",
    "        # Tags \n",
    "        tags = parse_review_tags(soup)\n",
    "        \n",
    "        # Thumb Scoring\n",
    "        thumb_scoring = parse_thumb_scoring(soup)\n",
    "        \n",
    "        # Review body\n",
    "        review_text = parse_review_text(soup)\n",
    "        \n",
    "        return {'meta_data': meta_data, 'rating_data': rating_data, 'tags': tags, 'thumb_scoring': thumb_scoring,\n",
    "                'review_text': review_text, 'rating_header': course_and_date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Utilities for an Entire RateMyProfessor Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_reviews(rmp_prof_url, selenium_driver, prof_name, courses):\n",
    "    \"\"\"Gets all the RateMyProfessor reviews for a given professor and places into a\n",
    "    dataframe. Only grabs reviews for classes in the provided courses.\n",
    "    \n",
    "    Args:\n",
    "        rmp_prof_url: A string containing the RateMyProfessor URL for the professor.\n",
    "        prof_name: A string containing the professor's name.\n",
    "        prof_courses: List of courses to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing all the appropriate reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    reviews_html = load_all_rmp_reviews(rmp_prof_url, selenium_driver)\n",
    "    soup = BeautifulSoup(reviews_html, 'html.parser')\n",
    "    \n",
    "    first_name, last_name = prof_name.split(' ', 1)\n",
    "    review_id_head = prof_name + '-'\n",
    "    counter = 1\n",
    "    \n",
    "    review_df = pd.DataFrame(columns=review_header_list)\n",
    "    \n",
    "    for review in soup.find_all('li'):\n",
    "        \n",
    "        if len(review.select('div[class*=\"Rating__StyledRating\"]')) != 0: # Avoid advertisement list items\n",
    "            data = parse_single_rmp_review(str(review), courses)\n",
    "\n",
    "            cur_review_id = review_id_head + str(counter)\n",
    "            counter = counter + 1\n",
    "            \n",
    "            if data: # Since the review could be of an undesired course\n",
    "                flattened_data = {'first_name': first_name, 'last_name': last_name, 'full_name': prof_name,\n",
    "                                  'review_id': cur_review_id}\n",
    "\n",
    "                for data_type, data_dict in data.items():\n",
    "                    \n",
    "                    for key, val in data_dict.items():\n",
    "                        flattened_data[key] = val\n",
    "\n",
    "                review_df = review_df.append(flattened_data, ignore_index=True)\n",
    "    \n",
    "    return review_df\n",
    "\n",
    "\n",
    "def parse_rmp_page(rmp_prof_url, headers, rmp_conn, selenium_driver, professor_name, courses):\n",
    "    \"\"\"Parses an entire RateMyProfessor professor page for overall stats & tags, and all\n",
    "    of their reviews. It will return two dataframes holding this information and insert\n",
    "    them into a database.\n",
    "    \n",
    "    Args:\n",
    "        rmp_prof_url: A string containing the RateMyProfessor URL for the professor.\n",
    "        headers: Request headers to use.\n",
    "        rmp_conn: Connection object to the RateMyProfessor database.\n",
    "        prof_name: A string containing the professor's name.\n",
    "        courses: List of courses to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of two dataframes, (overall statistics, all the reviews).\n",
    "    \"\"\"\n",
    "    \n",
    "    rmp_prof_page = requests.get(rmp_prof_url, headers=headers)\n",
    "    \n",
    "    if rmp_prof_page.status_code == 200:\n",
    "        soup = BeautifulSoup(rmp_prof_page.text, 'html.parser')\n",
    "        \n",
    "        # Professor stats\n",
    "        stats_container = soup.select('div[class*=\"TeacherInfo__StyledTeacher\"]')[0]\n",
    "        \n",
    "        prof_stats = get_rmp_prof_stats(str(stats_container))\n",
    "        prof_tags = get_rmp_prof_top_tags(str(stats_container))\n",
    "        \n",
    "        overall_df = rmp_prof_overall_to_dataframe(professor_name, prof_stats, prof_tags)\n",
    "        insert_rmp_professor_dataframe(rmp_conn, overall_df, 'professor_stats')\n",
    "        \n",
    "        # Professor reviews\n",
    "        all_reviews_df = get_rmp_prof_reviews(rmp_prof_url, selenium_driver, professor_name, courses)\n",
    "        insert_rmp_professor_dataframe(rmp_conn, all_reviews_df, 'reviews')\n",
    "        \n",
    "        return (overall_df, all_reviews_df)\n",
    "    else:\n",
    "        print(\"Error opening the RateMyProfessor professor page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape and Parse All Professors Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nonexistant_rmp_data(rmp_db, professor):\n",
    "    \"\"\"Marks a professor as not having a page and fills professor's overall statistics dataframe\n",
    "    with empty values so that it may be placed into the database and not re-queried for later.\n",
    "    \n",
    "    Args:\n",
    "        rmp_db: Connection object to the RateMyProfessor database.\n",
    "        professor: String containing the name of the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    empty_tags = tags_to_dict([])\n",
    "    empty_stats = {'rating': 0, 'take_again': 0, 'difficulty': 0, 'rating_count': 0}\n",
    "    \n",
    "    # Professor stats\n",
    "    overall_df = rmp_prof_overall_to_dataframe(professor, empty_stats, empty_tags, page_exists=0)\n",
    "    insert_rmp_professor_dataframe(rmp_db, overall_df, 'professor_stats')\n",
    "    \n",
    "    return None\n",
    "    \n",
    "    \n",
    "def parse_rmp_all_professors(rmp_db_filepath, professors, provided_courses, force_scrape=False):\n",
    "    \"\"\"Scrapes and parses all professors, storing the data in a database and returning a\n",
    "    list of dataframes for stats and reviews.\n",
    "    \n",
    "    Args:\n",
    "        rmp_db_filepath: String containing the filepath to the appropriate database.\n",
    "        professors: Dictionary of professors to list of courses.\n",
    "        force_scrape (optional, default=False): Forces a scrape of RateMyProfessors even if already done.\n",
    "        \n",
    "    Returns:\n",
    "        The tuple (stats, reviews) where each is a list of dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_major_stats = []\n",
    "    all_major_reviews = []\n",
    "    \n",
    "    rmp_db = create_connection(rmp_db_filepath)\n",
    "    selenium_driver = start_selenium()\n",
    "    \n",
    "    try:\n",
    "        for professor, courses in professors.items():\n",
    "            overall_stats_df = None\n",
    "            all_reviews_df = None\n",
    "\n",
    "            # Read from database if the professor has already been scraped (only checks stats for confirmation)\n",
    "            if not force_scrape and is_professor_scraped(rmp_db, professor):\n",
    "                overall_stats_df = get_professor_stats_from_db(rmp_db, professor)\n",
    "                all_reviews_df = get_professor_reviews_from_db(rmp_db, professor)\n",
    "\n",
    "                # Keep track of the dataframes for each professor\n",
    "                all_major_stats.append(overall_stats_df)\n",
    "                all_major_reviews.append(all_reviews_df)\n",
    "\n",
    "            else:\n",
    "                # Get all the data from the professor's RateMyProfessor page\n",
    "                prof_rmp_url = query_rmp_for_professor_url(professor, headers, params)\n",
    "\n",
    "                # If the professor has a RateMyProfessor page\n",
    "                if prof_rmp_url is not None:\n",
    "                    overall_stats_df, all_reviews_df = parse_rmp_page(prof_rmp_url, headers, rmp_db, selenium_driver, professor, provided_courses)\n",
    "\n",
    "                    # Keep track of the dataframes for each professor\n",
    "                    all_major_stats.append(overall_stats_df)\n",
    "                    all_major_reviews.append(all_reviews_df)\n",
    "                    \n",
    "                    # So we don't query RateMyProfessor too much\n",
    "                    time.sleep(1)\n",
    "\n",
    "                else:\n",
    "                    # Used to fill the stats table to show their page doesn't exist\n",
    "                    fill_nonexistant_rmp_data(rmp_db, professor)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Type error: \" + str(e))\n",
    "\n",
    "    finally:\n",
    "        rmp_db.close()\n",
    "        stop_selenium(selenium_driver)\n",
    "    \n",
    "        return (all_major_stats, all_major_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape and Parse All Computer Science Professors from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cmsc_stats, all_cmsc_reviews = parse_rmp_all_professors(cmsc_rmp_db_filepath, cmsc_professors, cmsc_course_ids)\n",
    "\n",
    "merged_cmsc_stats = pd.concat(all_cmsc_stats)\n",
    "merged_cmsc_reviews = pd.concat(all_cmsc_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>page_exists</th>\n",
       "      <th>rating</th>\n",
       "      <th>take_again</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>gives_good_feedback</th>\n",
       "      <th>...</th>\n",
       "      <th>group_projects</th>\n",
       "      <th>clear_grading_criteria</th>\n",
       "      <th>hilarious</th>\n",
       "      <th>beware_of_pop_quizes</th>\n",
       "      <th>amazing_lectures</th>\n",
       "      <th>lecture_heavy</th>\n",
       "      <th>caring</th>\n",
       "      <th>extra_credit</th>\n",
       "      <th>so_many_papers</th>\n",
       "      <th>tough_grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Fawzi</td>\n",
       "      <td>Emad</td>\n",
       "      <td>Fawzi Emad</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Ilchul</td>\n",
       "      <td>Yoon</td>\n",
       "      <td>Ilchul Yoon</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>Padua-Perez</td>\n",
       "      <td>Nelson Padua-Perez</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.1</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Pedram</td>\n",
       "      <td>Sadeghian</td>\n",
       "      <td>Pedram Sadeghian</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Anwar</td>\n",
       "      <td>Mamat</td>\n",
       "      <td>Anwar Mamat</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3.3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id first_name    last_name           full_name page_exists  rating  \\\n",
       "0  1.0      Fawzi         Emad          Fawzi Emad           1     4.4   \n",
       "0  2.0     Ilchul         Yoon         Ilchul Yoon           1     2.1   \n",
       "0  3.0     Nelson  Padua-Perez  Nelson Padua-Perez           1     4.0   \n",
       "0  4.0     Pedram    Sadeghian    Pedram Sadeghian           1     3.0   \n",
       "0  5.0      Anwar        Mamat         Anwar Mamat           1     3.1   \n",
       "\n",
       "   take_again  difficulty rating_count gives_good_feedback  ...  \\\n",
       "0        0.83         3.1          114                   0  ...   \n",
       "0        0.16         4.2           33                   0  ...   \n",
       "0        0.80         3.1           94                   0  ...   \n",
       "0        0.55         3.5           21                   0  ...   \n",
       "0        0.69         3.3           20                   0  ...   \n",
       "\n",
       "  group_projects clear_grading_criteria hilarious beware_of_pop_quizes  \\\n",
       "0              0                      0         1                    0   \n",
       "0              0                      0         0                    0   \n",
       "0              0                      0         1                    0   \n",
       "0              0                      0         0                    0   \n",
       "0              1                      1         1                    0   \n",
       "\n",
       "  amazing_lectures lecture_heavy caring extra_credit so_many_papers  \\\n",
       "0                1             0      0            0              0   \n",
       "0                0             1      0            0              0   \n",
       "0                1             0      1            0              0   \n",
       "0                0             1      0            0              0   \n",
       "0                0             0      0            0              0   \n",
       "\n",
       "  tough_grader  \n",
       "0            0  \n",
       "0            1  \n",
       "0            0  \n",
       "0            1  \n",
       "0            1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_cmsc_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape and Parse All Business Management Professors from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bmgt_stats, all_bmgt_reviews = parse_rmp_all_professors(bmgt_rmp_db_filepath, bmgt_professors, bmgt_course_ids)\n",
    "\n",
    "merged_bmgt_stats = pd.concat(all_bmgt_stats)\n",
    "merged_bmgt_reviews = pd.concat(all_bmgt_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>page_exists</th>\n",
       "      <th>rating</th>\n",
       "      <th>take_again</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>gives_good_feedback</th>\n",
       "      <th>...</th>\n",
       "      <th>group_projects</th>\n",
       "      <th>clear_grading_criteria</th>\n",
       "      <th>hilarious</th>\n",
       "      <th>beware_of_pop_quizes</th>\n",
       "      <th>amazing_lectures</th>\n",
       "      <th>lecture_heavy</th>\n",
       "      <th>caring</th>\n",
       "      <th>extra_credit</th>\n",
       "      <th>so_many_papers</th>\n",
       "      <th>tough_grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>Miller</td>\n",
       "      <td>Jeff Miller</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.8</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Cody</td>\n",
       "      <td>Hyman</td>\n",
       "      <td>Cody Hyman</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Progyan</td>\n",
       "      <td>Basu</td>\n",
       "      <td>Progyan Basu</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.9</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Gary</td>\n",
       "      <td>Bulmash</td>\n",
       "      <td>Gary Bulmash</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ai</td>\n",
       "      <td>Ren</td>\n",
       "      <td>Ai Ren</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id first_name last_name     full_name page_exists  rating  take_again  \\\n",
       "0  1.0       Jeff    Miller   Jeff Miller           1     3.5        0.52   \n",
       "0  2.0       Cody     Hyman    Cody Hyman           1     5.0        1.00   \n",
       "0  NaN    Progyan      Basu  Progyan Basu           1     3.9        0.85   \n",
       "0  NaN       Gary   Bulmash  Gary Bulmash           1     4.2        0.86   \n",
       "0  NaN         Ai       Ren        Ai Ren           1     3.3        0.50   \n",
       "\n",
       "   difficulty rating_count gives_good_feedback  ... group_projects  \\\n",
       "0         2.8           86                   0  ...              0   \n",
       "0         2.0            1                   1  ...              0   \n",
       "0         3.9           39                   0  ...              0   \n",
       "0         3.0           48                   0  ...              0   \n",
       "0         4.6            4                   1  ...              0   \n",
       "\n",
       "  clear_grading_criteria hilarious beware_of_pop_quizes amazing_lectures  \\\n",
       "0                      0         1                    0                1   \n",
       "0                      1         0                    0                0   \n",
       "0                      1         0                    0                0   \n",
       "0                      1         0                    0                0   \n",
       "0                      1         0                    0                0   \n",
       "\n",
       "  lecture_heavy caring extra_credit so_many_papers tough_grader  \n",
       "0             0      0            0              0            0  \n",
       "0             0      0            0              0            0  \n",
       "0             0      0            0              0            0  \n",
       "0             0      1            0              0            0  \n",
       "0             0      0            1              0            1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_bmgt_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Parse Data from PlanetTerp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse All Computer Science Professors Professors from PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://api.planetterp.com/#get-a-professor\n",
    "planetterp_url = \"https://api.planetterp.com/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse All Business Management Professors from PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D', 'D-', 'F+', 'F', 'F-']\n"
     ]
    }
   ],
   "source": [
    "temp = [ [x + '+', x, x + '-'] for x in grade_possibilities]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
