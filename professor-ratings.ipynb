{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Computer Science versus Business Management Introductory Course Professors Reviews and Their Trends Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "William Ingold, Erik Kelemen, Ashish Manda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Introductory Course Professors From UMD.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "professors_url = \"https://api.umd.io/v1/professors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for saving professor data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import path\n",
    "\n",
    "cmsc_professor_names_filepath = './data/cmsc_professor_names.csv'\n",
    "bmgt_professor_names_filepath = './data/bmgt_professor_names.csv'\n",
    "\n",
    "have_cmsc_professors = path.exists(cmsc_professor_names_filepath)\n",
    "have_bmgt_professors = path.exists(bmgt_professor_names_filepath)\n",
    "\n",
    "def read_professor_name_data(professor_filepath):\n",
    "    \"\"\"Reads the professor names and their courses from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professor_filepath: String holding a filepath to the professor csv file.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of professor names to a set of courses they have taught.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(professor_filepath, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "\n",
    "        professors = {}\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if line_count != 0:\n",
    "                professors[row['name']] = set([course for course in row['courses'].split(' ')])\n",
    "            line_count += 1\n",
    "\n",
    "        return professors\n",
    "\n",
    "def save_professor_data(professors, filepath):\n",
    "    \"\"\"Saves the professor names and their courses to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professors: A dictionary of professor name keys and a set of courses for values.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = ['name', 'courses']\n",
    "    try:\n",
    "        with open(filepath, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for name, courses in professors.items():\n",
    "                writer.writerow({'name': name, 'courses': ' '.join(courses)})\n",
    "                \n",
    "    except IOError:\n",
    "        print(\"Error in writing the CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility to actually grab professors based on a list of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_professors_for_courses(course_ids):\n",
    "    \"\"\"Gets all the professors for the given course_ids and returns a list of them.\n",
    "    \n",
    "    Args:\n",
    "        course_ids: A list of course ids (e.g. ['CMSC216', CMSC250']).\n",
    "        \n",
    "    Returns:\n",
    "        List of professors that teach the given courses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    professors = {}\n",
    "    \n",
    "    for course_id in course_ids:\n",
    "        params = {'course_id': course_id}\n",
    "\n",
    "        response = requests.get(professors_url, params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "\n",
    "            for item in response.json():\n",
    "                name = item['name']\n",
    "\n",
    "                if name in professors:\n",
    "                    professors[name].add(course_id)\n",
    "                else:\n",
    "                    professors[name] = {course_id}\n",
    "\n",
    "    return professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Computer Science Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fawzi Emad': {'CMSC250', 'CMSC131', 'CMSC132'}, 'Ilchul Yoon': {'CMSC216', 'CMSC131', 'CMSC132'}, 'Nelson Padua-Perez': {'CMSC216', 'CMSC131', 'CMSC132'}, 'Pedram Sadeghian': {'CMSC131', 'CMSC132'}, 'Anwar Mamat': {'CMSC132'}, 'Laurence Herman': {'CMSC216', 'CMSC132'}, 'A Shankar': {'CMSC216'}, 'Aditya Acharya': {'CMSC250'}, 'Alexander Brassel': {'CMSC250'}, 'Clyde Kruskal': {'CMSC250'}, 'David Sekora': {'CMSC250'}, 'Donald Perlis': {'CMSC250'}, 'Jason Filippou': {'CMSC250'}, 'Mohammad Nayeem Teli': {'CMSC250'}, 'Roger Eastman': {'CMSC250'}}\n"
     ]
    }
   ],
   "source": [
    "cmsc_course_ids = [\"CMSC131\", \"CMSC132\", \"CMSC216\", \"CMSC250\"]\n",
    "\n",
    "# TODO: Dr. Eastman has taught CMSC131, per RateMyProfessor, but wasn't given via UMD.IO\n",
    "\n",
    "# Only query the UMD.io API if we don't have the data\n",
    "if not have_cmsc_professors:\n",
    "    cmsc_professors = get_professors_for_courses(cmsc_course_ids)\n",
    "    save_professor_data(cmsc_professors, cmsc_professor_names_filepath)\n",
    "    have_cmsc_professors = True\n",
    "else: \n",
    "    cmsc_professors = read_professor_name_data(cmsc_professor_names_filepath)\n",
    "\n",
    "    if not cmsc_professors:\n",
    "        print(\"Error response from umd.io API\")\n",
    "\n",
    "if 'Iason Filippou' in cmsc_professors:\n",
    "    cmsc_professors.pop('Iason Filippou') # A typo of Jason Filippou from the database\n",
    "    \n",
    "print(cmsc_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Business Management Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jeff Miller': {'BMGT110'}, 'Cody Hyman': {'BMGT220'}, 'Laurel Mazur': {'BMGT221', 'BMGT220'}, 'Progyan Basu': {'BMGT220'}, 'Viktoriya Zotova': {'BMGT220'}, 'Gary Bulmash': {'BMGT221'}, 'Gerald Ward': {'BMGT221'}, 'Ai Ren': {'BMGT230'}, 'Daehoon Noh': {'BMGT230'}, 'Erich Studer-Ellis': {'BMGT230'}, 'Huan Cao': {'BMGT230'}, 'Radu Lazar': {'BMGT230'}, 'Shubham Akshat': {'BMGT230'}, 'Ziwei Cao': {'BMGT230'}}\n"
     ]
    }
   ],
   "source": [
    "bmgt_course_ids = [\"BMGT110\", \"BMGT220\", \"BMGT221\", \"BMGT230\"]\n",
    "\n",
    "# Only query the UMD.io API if we don't have the data\n",
    "if not have_bmgt_professors:\n",
    "    bmgt_professors = get_professors_for_courses(bmgt_course_ids)\n",
    "    save_professor_data(bmgt_professors, bmgt_professor_names_filepath)\n",
    "    have_bmgt_professors = True\n",
    "else:\n",
    "    bmgt_professors = read_professor_name_data(bmgt_professor_names_filepath)\n",
    "\n",
    "    if not bmgt_professors:\n",
    "        print(\"Error response from umd.io API\")\n",
    "\n",
    "print(bmgt_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Databases to Hold Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# Setup database presets\n",
    "db_filepath = './data/db/'\n",
    "bmgt_rmp_db_filepath = db_filepath + 'bmgt_rmp.db'\n",
    "cmsc_rmp_db_filepath = db_filepath + 'cmsc_rmp.db'\n",
    "\n",
    "cmsc_rmp_db_exists = path.exists(cmsc_rmp_db_filepath)\n",
    "bmgt_rmp_db_exists = path.exists(bmgt_rmp_db_filepath)\n",
    "\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\"Create a connection to the provided database file.\n",
    "    \n",
    "    Args:\n",
    "        db_file: A string holding the filepath to a database.\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    print(db_file)\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def execute_create_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    \n",
    "def execute_insert_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        conn.commit()\n",
    "        \n",
    "        return c.lastrowid\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def execute_query_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        \n",
    "        return c.fetchall()\n",
    "    \n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RateMyProfessor Specific Database Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/db/cmsc_rmp.db\n",
      "./data/db/bmgt_rmp.db\n"
     ]
    }
   ],
   "source": [
    "def create_rmp_tables(rmp_conn):\n",
    "    \"\"\"Create the stats and review tables for RateMyProfessors data.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessors database.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_table = \"\"\" CREATE TABLE IF NOT EXISTS professor_stats (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        rating REAL,\n",
    "                        take_again REAL,\n",
    "                        difficulty REAL,\n",
    "                        rating_count INTEGER NOT NULL,\n",
    "                        gives_good_feedback INTEGER,\n",
    "                        respected INTEGER,\n",
    "                        lots_of_homework INTEGER,\n",
    "                        accessible_outside_class INTEGER,\n",
    "                        get_ready_to_read INTEGER,\n",
    "                        participation_matters INTEGER,\n",
    "                        skip_class_wont_pass INTEGER,\n",
    "                        inspirational INTEGER,\n",
    "                        graded_by_few_things INTEGER,\n",
    "                        test_heavy INTEGER,\n",
    "                        group_projects INTEGER,\n",
    "                        clear_grading_criteria INTEGER,\n",
    "                        hilarious INTEGER,\n",
    "                        beware_of_pop_quizes INTEGER,\n",
    "                        amazing_lectures INTEGER,\n",
    "                        lecture_heavy INTEGER,\n",
    "                        caring INTEGER,\n",
    "                        extra_credit INTEGER,\n",
    "                        so_many_papers INTEGER,\n",
    "                        tough_grader INTEGER\n",
    "                    ) \"\"\"\n",
    "    \n",
    "    # TODO: Review id format? <professor last name>-<#> ?\n",
    "    review_table = \"\"\" CREATE TABLE IF NOT EXISTS reviews (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        review_id TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL,\n",
    "                        course TEXT NOT NULL,\n",
    "                        date INTEGER NOT NULL,\n",
    "                        body TEXT NOT NULL,\n",
    "                        thumb_up INTEGER,\n",
    "                        thumb_down INTEGER,\n",
    "                        quality REAL NOT NULL,\n",
    "                        difficulty REAL NOT NULL,\n",
    "                        would_take_again INTEGER NOT NULL,\n",
    "                        for_credit INTEGER NOT NULL,\n",
    "                        textbook INTEGER NOT NULL,\n",
    "                        attendance INTEGER,\n",
    "                        grade TEXT,\n",
    "                        online_class INTEGER,\n",
    "                        gives_good_feedback INTEGER,\n",
    "                        respected INTEGER,\n",
    "                        lots_of_homework INTEGER,\n",
    "                        accessible_outside_class INTEGER,\n",
    "                        get_ready_to_read INTEGER,\n",
    "                        participation_matters INTEGER,\n",
    "                        skip_class_wont_pass INTEGER,\n",
    "                        inspirational INTEGER,\n",
    "                        graded_by_few_things INTEGER,\n",
    "                        test_heavy INTEGER,\n",
    "                        group_projects INTEGER,\n",
    "                        clear_grading_criteria INTEGER,\n",
    "                        hilarious INTEGER,\n",
    "                        beware_of_pop_quizes INTEGER,\n",
    "                        amazing_lectures INTEGER,\n",
    "                        lecture_heavy INTEGER,\n",
    "                        caring INTEGER,\n",
    "                        extra_credit INTEGER,\n",
    "                        so_many_papers INTEGER,\n",
    "                        tough_grader INTEGER\n",
    "                   ) \"\"\"\n",
    "    \n",
    "    execute_create_command(rmp_conn, stats_table)\n",
    "    execute_create_command(rmp_conn, review_table)\n",
    "\n",
    "# Create the CMSC and BMGT database with the two tables\n",
    "cmsc_rmp_db = create_connection(cmsc_rmp_db_filepath)\n",
    "bmgt_rmp_db = create_connection(bmgt_rmp_db_filepath)\n",
    "\n",
    "create_rmp_tables(cmsc_rmp_db)\n",
    "create_rmp_tables(bmgt_rmp_db)\n",
    "\n",
    "# Close for now, will reopen when writing to them\n",
    "cmsc_rmp_db.close()\n",
    "bmgt_rmp_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rmp_scraped(rmp_conn, professor_name):\n",
    "    \"\"\"Returns if the professor's RateMyProfessors page has been scraped already.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to the appropriate rmp database.\n",
    "        professor_name: String holding the professor's name.\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_command = \"\"\"SELECT\n",
    "                        full_name\n",
    "                    FROM\n",
    "                        professor_stats ps\n",
    "                    WHERE\n",
    "                        full_name LIKE ?\"\"\"\n",
    "    \n",
    "    params=('%'+professor_name+'%',)\n",
    "    \n",
    "    result = execute_query_command(rmp_conn, sql_command, params)\n",
    "    \n",
    "    return len(result) != 0\n",
    "\n",
    "\n",
    "def get_rmp_stats_from_db(rmp_conn, professor):\n",
    "    \"\"\"Reads the professor_stats table into a pandas dataframe and returns it.\"\"\"\n",
    "    \n",
    "    sql_query = \"\"\"SELECT * FROM professor_stats WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[professor])\n",
    "\n",
    "def get_rmp_reviews_from_db(rmp_conn, professor):\n",
    "    \"\"\"Reads the reviews table into a pandas dataframe and returns it.\"\"\"\n",
    "    \n",
    "    sql_query = \"\"\"SELECT * FROM reviews WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[professor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using dataframes, but single table to hold all stats and reviews instead of individual tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_rmp_dataframe_insert(rmp_conn, table_name, column_list, values):\n",
    "    \"\"\"Executes an insert to the provided database and table, using the\n",
    "    column headers and values provided as well.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessor database.\n",
    "        table_name: String holding a table name to insert into ('reviews' or 'professor_stats')\n",
    "        values: List of values corresponding to the column headers to insert.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Question mark for each value to be filled, don't want a trailing comma\n",
    "    question_marks = \"?,\" * (len(column_list) - 1)\n",
    "    question_marks = question_marks + \"?\"\n",
    "    \n",
    "    column_names = \",\".join(column_list)\n",
    "    \n",
    "    insert_rmp_sql = \"\"\"INSERT INTO {table_name} (\n",
    "                                {column_names}\n",
    "                           )\n",
    "                           VALUES({question_marks})\n",
    "                           \"\"\".format(table_name=table_name, question_marks=question_marks, column_names=column_names)\n",
    "    \n",
    "    # TODO: Need to surround with % ?\n",
    "    values = tuple(values)\n",
    "    \n",
    "    return execute_insert_command(rmp_conn, insert_rmp_sql, values)\n",
    "    \n",
    "    \n",
    "def insert_rmp_professor_dataframe(rmp_conn, df, table_name):\n",
    "    \"\"\"Inserts all rows of a given dataframe to the RMP database's table.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessor database.\n",
    "        df: Pandas DataFrame object containing data to insert.\n",
    "        table_name: String holding a table name to insert into ('reviews' or 'professor_stats')\n",
    "    \"\"\"\n",
    "    \n",
    "    column_list = list(df.columns)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        execute_rmp_dataframe_insert(rmp_conn, table_name, column_list, row.array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO: Alternative database structure, where each professor has its own tables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_rmp_professor_overall_table(rmp_conn, professor_name, overall_df):\n",
    "    table_name = professor_name + \"_stats\"\n",
    "    overall_df.to_sql(table_name, con=rmp_conn, if_exists='append')\n",
    "    \n",
    "def insert_rmp_professor_reviews_table(rmp_conn, professor_name, review_df):\n",
    "    table_name = professor_name + \"_reviews\"\n",
    "    review_df.to_sql(table_name, con=rmp_conn, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlanetTerp Database Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Parse Data from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data needed for requesting data from RateMyProfessor\n",
    "ratemyprofessor_url = \"https://www.ratemyprofessors.com/search.jsp\"\n",
    "params = {'queryoption':'HEADER', 'schoolID':'1270', 'queryBy':'teacherName', 'schoolName':'University+of+Maryland'}\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\",\n",
    "    \"Access-Control-Allow-Origin\": \"*\",\n",
    "    \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "    \"Access-Control-Allow-Methods\": \"GET\"\n",
    "}\n",
    "\n",
    "\n",
    "# List of tags that RateMyProfessor uses to describe professors, which are used for the database and dataframes\n",
    "tag_list = ['gives_good_feedback', 'respected', 'lots_of_homework', 'accessible_outside_class',\n",
    "           'get_ready_to_read', 'participation_matters', 'inspirational',\n",
    "           'graded_by_few_things', 'test_heavy', 'group_projects', 'clear_grading_criteria', \n",
    "           'hilarious', 'beware_of_pop_quizes', 'amazing_lectures', 'lecture_heavy', 'caring',\n",
    "           'extra_credit', 'so_many_papers', 'tough_grader', 'skip_class_wont_pass']\n",
    "\n",
    "# Want to tie the code friendly tag names to what is found on a RateMyProfessor page\n",
    "text_tag_list = [' '.join(x.split('_')) for x in tag_list]\n",
    "text_tag_list.remove('skip class wont pass')\n",
    "text_tag_list.append(\"skip class? you won't pass.\")\n",
    "\n",
    "# both tag_list and text_tag_list in same order, and correspond to one another\n",
    "text_tag_dict = {text_tag_list[i]: tag_list[i] for i in range(len(text_tag_list))}\n",
    "\n",
    "# These are the column headers for a professor's overall statistics found at the top of the page\n",
    "overall_header_list = ['first_name', 'last_name', 'full_name', 'rating', 'take_again', 'difficulty',\n",
    "                      'rating_count'] + tag_list\n",
    "\n",
    "# Review post column headers. The meta list is the row of top meta responses (like 'Grade: A-').\n",
    "review_meta_list = ['would_take_again', 'grade', 'textbook', 'online_class', 'for_credit', 'attendance']\n",
    "review_text_meta_list = [' '.join(x.split('_')) for x in review_meta_list]\n",
    "review_meta_dict = {review_text_meta_list[i]: review_meta_list[i] for i in range(len(review_meta_list))}\n",
    "        \n",
    "review_header_list = ['review_id', 'course', 'date', 'quality', 'difficulty', 'body',\n",
    "                      'thumb_up', 'thumb_down'] + review_meta_list + tag_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_dict(provided_tags):\n",
    "    \"\"\"Turns the list of text tags (e.g. skip class? you won't pass) into a dictionary\n",
    "    of approriately named tags that work for database columns and if they were present.\n",
    "    \n",
    "    Args:\n",
    "        provided_tags: A list of space separated tags scraped from the RMP page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of {tag: 1 or 0} on whether a tag was used to describe the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_dict = {val: 0 for val in text_tag_dict.values()}\n",
    "    \n",
    "    for tag in provided_tags:\n",
    "        if tag.lower() in text_tag_dict.keys():\n",
    "            tag_dict[text_tag_dict[tag.lower()]] = 1\n",
    "            \n",
    "    return tag_dict\n",
    "\n",
    "def meta_to_dict(provided_meta):\n",
    "    \"\"\"Turns the dictionary of meta tags (e.g. Would Take Again: No) into a dictionary\n",
    "    of appropriately named tags that work for database columns and values if they were present.\n",
    "    \n",
    "    Args:\n",
    "        provided_meta: A dictionary of meta information from a review.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of {meta: 1 or 0} on whether a meta was used on the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    meta_dict = {val: 0 for val in review_meta_list}\n",
    "    \n",
    "    for meta, response in provided_meta.items():\n",
    "        value = 0\n",
    "        \n",
    "        if meta.lower() in review_meta_dict.keys():\n",
    "            \n",
    "            if response.lower() == \"yes\" or response.lower() == \"mandatory\":\n",
    "                value = 1\n",
    "                \n",
    "            if meta.lower() == \"grade\":\n",
    "                value = response\n",
    "            \n",
    "            meta_dict[review_meta_dict[meta.lower()]] = value\n",
    "            \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying RateMyProfessor and Getting the Professor's URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rmp_professor_url(html_doc):\n",
    "    \"\"\"Finds the professor's URL on the search page and returns it.\n",
    "    \n",
    "    Args:\n",
    "        html_doc: A string containing an HTML document.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page (if found).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    no_results = soup.find('div[class*=\"NoResultsFoundArea__StyledNoResultsFound\"]')\n",
    "    partial_url = soup.find('li', class_='listing PROFESSOR')\n",
    "    \n",
    "    # Sometimes RMP does the search differntly, so it'll be elsewhere\n",
    "    diff_location = soup.find('a', attrs={'class': lambda x: 'TeacherCard__StyledTeacherCard' in x if x else False}, href=True)\n",
    "    \n",
    "    # The professor may not be reviewed\n",
    "    if no_results is None and partial_url and len(partial_url) != 0:\n",
    "        if diff_location:\n",
    "            partial_url = diff_location['href']\n",
    "        else:\n",
    "            partial_url = partial_url.find('a', href=True)\n",
    "\n",
    "        if partial_url:\n",
    "            main_url = \"https://www.ratemyprofessors.com\"\n",
    "            return main_url + partial_url['href']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def query_rmp_for_professor_url(professor_name, headers, params):\n",
    "    \"\"\"Queries RateMyProfessor for the professor, given the parameters and headers.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: The <first name> <last name> of the professor.\n",
    "        headers: Dictionary of headers for the get request.\n",
    "        params: Dictionary of parameters for the get request.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page after searching for it (if found).\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    params['query'] = professor_name\n",
    "    \n",
    "    response = requests.get(ratemyprofessor_url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        url = find_rmp_professor_url(response.text)\n",
    "        \n",
    "        if url is not None:\n",
    "            return url\n",
    "        else:\n",
    "            print(\"Professor {name} has not been reviewed.\".format(name=professor_name))\n",
    "            return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing the Professor Overall Information (Stats and Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_stats(page_text):\n",
    "    \"\"\"Parses the professor's stats from their page and returns them. Namely their overall rating, \n",
    "    how many would take again, overall difficulty and how many ratings they have on RateMyProfessor.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing their rating, take again percentage, difficulty rating, and rating count.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    rating_score = soup.select('div[class*=\"RatingValue__Numerator\"]')\n",
    "    \n",
    "    if rating_score is not None:\n",
    "        rating_score = float(rating_score[0].text)\n",
    "    else:\n",
    "        print('Rating score error: \\n')\n",
    "        print(soup)\n",
    "    \n",
    "    feedback = soup.select('div[class*=\"TeacherFeedback__StyledTeacherFeedback\"]')[0].select('div[class*=\"FeedbackItem__FeedbackNumber\"]')\n",
    "    \n",
    "    take_again = float(feedback[0].text[:-1]) / 100\n",
    "    difficulty = float(feedback[1].text)\n",
    "    \n",
    "    rating_count = soup.select('div[class*=\"RatingValue__NumRatings\"]')[0].select('a')[0].text\n",
    "    rating_count = ''.join([x for x in rating_count if x.isdigit()])\n",
    "    rating_count = int(rating_count)\n",
    "    \n",
    "    return {'rating': rating_score, 'take_again': take_again, 'difficulty': difficulty, 'rating_count': rating_count}\n",
    "\n",
    "\n",
    "def get_rmp_prof_top_tags(page_text):\n",
    "    \"\"\"Parses and returns the professor's top tags.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tags describing the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    tags = []\n",
    "    unparsed_tags = soup.select('div[class*=\"TeacherTags__TagsContainer\"]')[0].select('span')\n",
    "    \n",
    "    for tag in unparsed_tags:\n",
    "        tags.append(tag.text)\n",
    "        \n",
    "    return tags_to_dict(tags)\n",
    "\n",
    "\n",
    "def rmp_prof_overall_to_dataframe(professor_name, stats, tags):\n",
    "    \"\"\"Combines the professor's overall stats and tags into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: String holding the professor's name.\n",
    "        stats: A dictionary holding the overall stats (e.g. 'would_take_again': .83)\n",
    "        tags: A dictionary holding the tags associated with a professor (e.g. {'caring': 1})\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing the combination of professor name, stats, and tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    overall_df = pd.DataFrame(columns=overall_header_list)\n",
    "    \n",
    "    first_name, last_name = professor_name.split(' ', 1)\n",
    "    overall_dict = {'first_name': first_name, 'last_name': last_name, 'full_name': professor_name}\n",
    "    \n",
    "    overall_dict.update(stats)\n",
    "    overall_dict.update(tags)\n",
    "    \n",
    "    overall_df = overall_df.append(overall_dict, ignore_index=True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Selenium to Load All Professor Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_selenium():\n",
    "    \"\"\"Starts up the Selenium browser.\"\"\"\n",
    "    driver = webdriver.Firefox(executable_path='./bin/geckodriver.exe')\n",
    "    return driver\n",
    "    \n",
    "def stop_selenium(driver):\n",
    "    \"\"\"Shutdown the Selenium browser.\"\"\"\n",
    "    driver.close()\n",
    "    driver.quit()\n",
    "    \n",
    "def load_all_rmp_reviews(page_url, driver):\n",
    "    \"\"\"Loads all the reviews for a given porfessor and returns the text of all of them.\n",
    "    \n",
    "    Args:\n",
    "        page_url: The URL for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the HTML for all the reviews.\n",
    "    \"\"\"\n",
    "\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # RateMyProfessors has a cookies pop up that overlays the website, it needs to be closed first\n",
    "    time.sleep(0.5)\n",
    "    close_cookies = driver.find_elements(By.XPATH, '//button[text()=\"Close\"]')\n",
    "    \n",
    "    if close_cookies:\n",
    "        close_cookies[0].click()\n",
    "        \n",
    "    load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "    \n",
    "    # RateMyProfessors paginates the reviews via Javascript, so we must continually load more while the button is present\n",
    "    while load_more:\n",
    "        load_more[0].click()\n",
    "        time.sleep(1)\n",
    "        load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "        \n",
    "        \n",
    "    all_reviews = driver.find_element_by_id('ratingsList').get_attribute('outerHTML')\n",
    "    \n",
    "    \n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Utilities for a Single Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def string_date_to_unix(date_str):\n",
    "    \"\"\"Turns the RateMyProfessor date format (e.g. Nov 23rd, 2020) into a\n",
    "    UTC timestamp. Assumes the date is already in UTC.\n",
    "    \n",
    "    Args:\n",
    "        date_str: A string containing the RateMyProfessor review date.\n",
    "        \n",
    "    Returns:\n",
    "        A UTC timestamp corresponding to the date provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split into month, day, year\n",
    "    date_split = date_str.split(' ')\n",
    "    day = date_split[1]\n",
    "    \n",
    "    # Remove comma and suffix for day\n",
    "    day = day[:-3]\n",
    "    \n",
    "    # Place the day back into the list and join everything back together\n",
    "    date_split[1] = day\n",
    "    remade_date_str = (' ').join(date_split)\n",
    "    \n",
    "    # Change into UTC time\n",
    "    datetime_obj = datetime.datetime.strptime(remade_date_str, '%b %d %Y')\n",
    "    utc_time = datetime_obj.timestamp()\n",
    "    \n",
    "    return utc_time\n",
    "    \n",
    "def parse_rating_header(soup):\n",
    "    \"\"\"Parses and returns the rating header for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the course and date for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_header = soup.select('div[class*=\"Rating__RatingInfo\"]')\n",
    "    \n",
    "    if len(rating_header) != 0:\n",
    "        course = rating_header[0].select('div[class*=\"RatingHeader__StyledClass\"]')[0].text.strip()\n",
    "        date = rating_header[0].select('div[class*=\"TimeStamp__StyledTimeStamp\"]')[0].text.strip()\n",
    "        \n",
    "        utc_time = string_date_to_unix(date)\n",
    "    else:\n",
    "        print(soup)\n",
    "    \n",
    "    return {'course': course, 'date': utc_time}\n",
    "\n",
    "def parse_meta_data(soup):\n",
    "    \"\"\"Parses and returns the meta data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data (e.g. Would Take Again) for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    course_meta = soup.select('div[class*=\"CourseMeta__StyledCourseMeta\"]')[0]\n",
    "    review_meta_data = {}\n",
    "\n",
    "    for meta_div in course_meta.select('div'):\n",
    "        meta_data = meta_div.text.split(':')\n",
    "        meta_name = meta_data[0].strip()\n",
    "        meta_value = meta_data[1].strip()\n",
    "\n",
    "        review_meta_data[meta_name] = meta_value\n",
    "\n",
    "    return meta_to_dict(review_meta_data)\n",
    "\n",
    "def parse_rating_data(soup):\n",
    "    \"\"\"Parses and returns the rating data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the rating data for the quality and difficulty for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_values_text = soup.select('div[class*=\"RatingValues__StyledRatingValues\"]')[0].select('div[class*=\"RatingValues__RatingValue\"]')\n",
    "    quality = rating_values_text[0].text\n",
    "    difficulty = rating_values_text[1].text\n",
    "\n",
    "    rating_data = {'quality': quality, 'difficulty': difficulty}\n",
    "    \n",
    "    return rating_data\n",
    "\n",
    "def parse_review_tags(soup):\n",
    "    \"\"\"Parses and returns the tags for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list containing the tags for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_container = soup.select('div[class*=\"RatingTags__StyledTags\"]')\n",
    "    tags = []\n",
    "    \n",
    "    if tag_container: # Since not all reviews add tags\n",
    "        unparsed_tags = tag_container[0].select('span')\n",
    "\n",
    "        for tag in unparsed_tags:\n",
    "            tags.append(tag.text)\n",
    "\n",
    "    return tags_to_dict(tags)\n",
    "    \n",
    "def parse_thumb_scoring(soup):\n",
    "    \"\"\"Parses and returns the thumb scoring data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the thumb scoring data for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    thumb_container = soup.select('div[class*=\"RatingFooter__StyledRatingFooter\"]')[0].select('div[class*=\"RatingFooter__HelpTotal\"]')\n",
    "\n",
    "    thumb_up = int(thumb_container[0].text.strip())\n",
    "    thumb_down = int(thumb_container[1].text.strip())\n",
    "    thumb_data = {'thumb_up': thumb_up, 'thumb_down': thumb_down}\n",
    "\n",
    "    return thumb_data\n",
    "\n",
    "def parse_review_text(soup):\n",
    "    \"\"\"Parses and returns the review body text for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the review text for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_text = soup.select('div[class*=\"Comments__StyledComments\"]')[0].text\n",
    "    \n",
    "    return {'body': review_text}\n",
    "    \n",
    "def parse_single_rmp_review(review_item, courses):\n",
    "    \"\"\"Parses and returns all data for a single review.\n",
    "    Namely it returns: Meta data, rating data, tags, thumb_scoring, and review text.\n",
    "    \n",
    "    Args:\n",
    "        review_item: A single review list item containing all the appropraite HTML.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data, rating data, tags, thumb_scoring, and review text\n",
    "        for a single review.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(review_item, 'html.parser')\n",
    "    \n",
    "    course_and_date = parse_rating_header(soup)\n",
    "    \n",
    "    # TODO: Loses course reviews like 'CMSC131CMSC132' where students combined multiple courses they took\n",
    "    if course_and_date['course'] in courses:\n",
    "        \n",
    "        # Meta data\n",
    "        meta_data = parse_meta_data(soup)\n",
    "        \n",
    "        # Rating data\n",
    "        rating_data = parse_rating_data(soup)\n",
    "        \n",
    "        # Tags \n",
    "        tags = parse_review_tags(soup)\n",
    "        \n",
    "        # Thumb Scoring\n",
    "        thumb_scoring = parse_thumb_scoring(soup)\n",
    "        \n",
    "        # Review body\n",
    "        review_text = parse_review_text(soup)\n",
    "        \n",
    "        return {'meta_data': meta_data, 'rating_data': rating_data, 'tags': tags, 'thumb_scoring': thumb_scoring,\n",
    "                'review_text': review_text, 'rating_header': course_and_date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Utilities for an Entire RateMyProfessor Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_reviews(rmp_prof_url, selenium_driver, prof_name, prof_courses):\n",
    "    \"\"\"Gets all the RateMyProfessor reviews for a given professor and places into a\n",
    "    dataframe. Only grabs reviews for classes in the provided courses.\n",
    "    \n",
    "    Args:\n",
    "        rmp_prof_url: A string containing the RateMyProfessor URL for the professor.\n",
    "        prof_name: A string containing the professor's name.\n",
    "        prof_courses: List of courses to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing all the appropriate reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    reviews_html = load_all_rmp_reviews(rmp_prof_url, selenium_driver)\n",
    "    soup = BeautifulSoup(reviews_html, 'html.parser')\n",
    "    \n",
    "    first_name, last_name = prof_name.split(' ', 1)\n",
    "    review_id_head = prof_name + '-'\n",
    "    counter = 1\n",
    "    \n",
    "    review_df = pd.DataFrame(columns=review_header_list)\n",
    "    \n",
    "    for review in soup.find_all('li'):\n",
    "        \n",
    "        if len(review.select('div[class*=\"Rating__StyledRating\"]')) != 0: # Avoid advertisement list items\n",
    "            data = parse_single_rmp_review(str(review), prof_courses)\n",
    "\n",
    "            cur_review_id = review_id_head + str(counter)\n",
    "            counter = counter + 1\n",
    "            \n",
    "            if data: # Since the review could be of an undesired course\n",
    "                flattened_data = {'first_name': first_name, 'last_name': last_name, 'full_name': prof_name,\n",
    "                                  'review_id': cur_review_id}\n",
    "\n",
    "                for data_type, data_dict in data.items():\n",
    "                    \n",
    "                    for key, val in data_dict.items():\n",
    "                        flattened_data[key] = val\n",
    "\n",
    "                review_df = review_df.append(flattened_data, ignore_index=True)\n",
    "    \n",
    "    return review_df\n",
    "\n",
    "\n",
    "def parse_rmp_page(rmp_prof_url, headers, rmp_conn, selenium_driver, professor_name, courses):\n",
    "    \"\"\"Parses an entire RateMyProfessor professor page for overall stats & tags, and all\n",
    "    of their reviews. It will return two dataframes holding this information and insert\n",
    "    them into a database.\n",
    "    \n",
    "    Args:\n",
    "        rmp_prof_url: A string containing the RateMyProfessor URL for the professor.\n",
    "        headers: Request headers to use.\n",
    "        rmp_conn: Connection object to the RateMyProfessor database.\n",
    "        prof_name: A string containing the professor's name.\n",
    "        courses: List of courses to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of two dataframes, (overall statistics, all the reviews).\n",
    "    \"\"\"\n",
    "    \n",
    "    rmp_prof_page = requests.get(rmp_prof_url, headers=headers)\n",
    "    \n",
    "    if rmp_prof_page.status_code == 200:\n",
    "        soup = BeautifulSoup(rmp_prof_page.text, 'html.parser')\n",
    "        \n",
    "        # Professor stats\n",
    "        stats_container = soup.select('div[class*=\"TeacherInfo__StyledTeacher\"]')[0]\n",
    "        \n",
    "        prof_stats = get_rmp_prof_stats(str(stats_container))\n",
    "        prof_tags = get_rmp_prof_top_tags(str(stats_container))\n",
    "        \n",
    "        overall_df = rmp_prof_overall_to_dataframe(professor_name, prof_stats, prof_tags)\n",
    "        insert_rmp_professor_dataframe(rmp_conn, overall_df, 'professor_stats')\n",
    "        \n",
    "        # Professor reviews\n",
    "        all_reviews_df = get_rmp_prof_reviews(rmp_prof_url, selenium_driver, professor_name, courses)\n",
    "        insert_rmp_professor_dataframe(rmp_conn, all_reviews_df, 'reviews')\n",
    "        \n",
    "        return (overall_df, all_reviews_df)\n",
    "    else:\n",
    "        print(\"Error opening the RateMyProfessor professor page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape and Parse All Professors Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rmp_all_professors(rmp_db_filepath, professors, force_scrape=False):\n",
    "    \"\"\"Scrapes and parses all professors, storing the data in a database and returning a\n",
    "    list of dataframes for stats and reviews.\n",
    "    \n",
    "    Args:\n",
    "        rmp_db_filepath: String containing the filepath to the appropriate database.\n",
    "        professors: Dictionary of professors to list of courses.\n",
    "        force_scrape (optional, default=False): Forces a scrape of RateMyProfessors even if already done.\n",
    "        \n",
    "    Returns:\n",
    "        The tuple (stats, reviews) where each is a list of dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    rmp_db = create_connection(rmp_db_filepath)\n",
    "    selenium_driver = start_selenium()\n",
    "    \n",
    "    all_major_stats = []\n",
    "    all_major_reviews = []\n",
    "\n",
    "    for professor, courses in professors.items():\n",
    "        overall_stats_df = None\n",
    "        all_reviews_df = None\n",
    "\n",
    "        # Read from database if the professor has already been scraped (only checks stats for confirmation)\n",
    "        if not force_scrape and is_rmp_scraped(rmp_db, professor):\n",
    "            overall_stats_df = get_rmp_stats_from_db(rmp_db, professor)\n",
    "            all_reviews_df = get_rmp_reviews_from_db(rmp_db, professor)\n",
    "\n",
    "        else:\n",
    "            # Get all the data from the professor's RateMyProfessor page\n",
    "            prof_rmp_url = query_rmp_for_professor_url(professor, headers, params)\n",
    "\n",
    "            if prof_rmp_url is not None:\n",
    "                overall_stats_df, all_reviews_df = parse_rmp_page(prof_rmp_url, headers, rmp_db, selenium_driver, professor, courses)\n",
    "\n",
    "            # So we don't query RateMyProfessor too much\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Keep track of the dataframes for each professor\n",
    "        all_major_stats.append(overall_stats_df)\n",
    "        all_major_reviews.append(all_reviews_df)\n",
    "\n",
    "    rmp_db.close()\n",
    "    stop_selenium(selenium_driver)\n",
    "    \n",
    "    return (all_major_stats, all_major_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape and Parse All Computer Science Professors from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/db/cmsc_rmp.db\n",
      "Professor Laurence Herman has not been reviewed.\n",
      "Professor A Shankar has not been reviewed.\n",
      "Professor Aditya Acharya has not been reviewed.\n",
      "Professor Alexander Brassel has not been reviewed.\n"
     ]
    }
   ],
   "source": [
    "all_cmsc_stats, all_cmsc_reviews = parse_rmp_all_professors(cmsc_rmp_db_filepath, cmsc_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape and Parse All Business Management Professors from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/db/bmgt_rmp.db\n",
      "Professor Laurel Mazur has not been reviewed.\n",
      "Professor Viktoriya Zotova has not been reviewed.\n",
      "Professor Gerald Ward has not been reviewed.\n",
      "Professor Daehoon Noh has not been reviewed.\n"
     ]
    }
   ],
   "source": [
    "all_bmgt_stats, all_bmgt_reviews = parse_rmp_all_professors(bmgt_rmp_db_filepath, bmgt_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Planetterp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse All Computer Science Professors Professors from PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse All Business Management Professors from PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
